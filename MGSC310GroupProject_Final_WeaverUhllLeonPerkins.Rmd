---
title: "Final Group Project"
author: "Amanda Weaver, John Uhl, Noah Perkins, Steve Leon"
subtitle: Predicting Song Popularity 
output:
  html_document:
    df_print: paged
  html_notebook: default
---

```{r setup, include=FALSE}


library(knitr)

# As long as you are working in a Rstudio Project file, you shouldn't need to 'hard code' directories like this 
# change to your own working directory
#knitr::opts_knit$set(root.dir = 'C:/Users/doosti/Desktop/MGSC_310')

# set seed to your own favorite number
set.seed(310)
options(width=70)
# if you want to prevent scientific format for numbers use this:
options(scipen=99)

# general rchunk code options
opts_chunk$set(tidy.opts=list(width.wrap=50),tidy=FALSE, size = "vsmall")
opts_chunk$set(message = FALSE,
               warning = FALSE,
               cache = TRUE,
               autodep = TRUE,
               cache.comments = FALSE,
               collapse = TRUE,
               fig.width = 5,  
               fig.height = 4,
               fig.align='center')

```

```{r setup_2}

# load all your libraries here
library(ISLR)
library(tidyverse)
library(rsample)
library(ggplot2)
library(ISLR2)
library(ggcorrplot)
library(forcats)
library(yardstick)
library(plotROC)
library(glmnet)
library(glmnetUtils)
library(randomForest)
library(randomForestExplainer)
library(MASS)
library(tree)
library(coefplot)
library(caret)
# note, do not run install.packages() inside a code chunk. install them in the console outside of a code chunk. 

```


Data Cleaning and Summary Statistics, with GGplots

```{r}
#code for Data Cleaning

#Original uncleaned  dataset link

# https://www.kaggle.com/datasets/salvatorerastelli/spotify-and-youtube


# import initial uncleaned data, change file path to be personal 
songs <- read.csv("Data Sets/Spotify_Youtube.csv")

# data cleaning and exploring
songs %>% glimpse()
songs %>% is.na %>% sum()

# drop missing values
songs_clean <- songs %>% drop_na() # drop 1169 rows with missing values
songs_clean %>% is.na %>% sum()
songs_clean %>% dim() # still have 19549 observations

# drop variables that are irrelevant to our model
songs_clean <- songs_clean %>% select(-c(Description, Url_spotify, Uri))

# factor binary variables
songs_clean <- songs_clean %>% mutate(Artist = factor(Artist),
                                      Licensed = as.logical(Licensed),
                                      official_video = as.logical(official_video),
                                      ViewsM = Views/1000000)

songs_clean %>% glimpse()
songs_clean %>% summary()

# make dummy variable for top10 artists
topArtist <- songs_clean %>% 
  group_by(Artist) %>% 
  summarize(ViewsM = n()) %>% 
  top_frac(0.1) %>% 
  mutate(topArtist = 1) %>% 
  select(-ViewsM)

songs_clean <- songs_clean %>% 
  left_join(topArtist, by = "Artist") %>% 
  mutate(topArtist = replace_na(topArtist, 0))

songs_clean <- songs_clean %>% 
  mutate(logDuration = log(Duration_ms),
         logViewsM = log(ViewsM))

songs_clean %>% glimpse()

#read songs_clean , change file path to be correct for your device 
write.csv(songs_clean,"Data Sets/songs_clean.csv", row.names=FALSE)

# RANDOM METRICS FOR WRITE UP 
# portion of observations that have less than 1 billion views
sum(songs_clean$ViewsM < 1000) / sum(songs_clean$ViewsM > 0)

# effect of official_video on Views
songs_clean %>% filter(official_video == TRUE) %>% summarize(mean(ViewsM))
songs_clean %>% filter(official_video == FALSE) %>% summarize(mean(ViewsM))

# portion of observations where official_video == TRUE
mean(songs_clean$official_video)
# correlation matrix of variables


# correlation matrix
cor_table <- cor(songs_clean %>% select_if(is.numeric))
cor_table

ggcorrplot(cor_table)

# data visualization

ggplot(songs_clean, aes(x = Danceability)) + geom_histogram(fill = "#9a0331ff") + 
  theme_minimal() + 
  labs(y = "Observations", title = "Danceability")

ggplot(songs_clean, aes(x = Loudness)) + geom_histogram(fill = "#9a0331ff") + 
  theme_minimal() + 
  labs(y = "Observations", title = "Loudness")

ggplot(songs_clean, aes(x = Energy)) + geom_histogram(fill = "#9a0331ff") + 
  theme_minimal() + 
  labs(y = "Observations", title = "Energy")

ggplot(songs_clean, aes(x = Speechiness)) + geom_histogram(fill = "#9a0331ff") + 
  theme_minimal() + 
  labs(y = "Observations", title = "Speechiness")

ggplot(songs_clean, aes(x = Acousticness)) + geom_histogram(fill = "#9a0331ff") + 
  theme_minimal() + 
  labs(y = "Observations", title = "Acousticness")

ggplot(songs_clean, aes(x = Duration_ms)) + geom_histogram(fill = "#9a0331ff") + 
  theme_minimal() + 
  labs(y = "Observations", x = "Duration (milliseconds)", title = "Duration (milliseconds)")

ggplot(songs_clean, aes(x = Valence)) + geom_histogram(fill = "#9a0331ff") + 
  theme_minimal() + 
  labs(y = "Observations", title = "Valence")

ggplot(songs_clean, aes(x = Liveness)) + geom_histogram(fill = "#9a0331ff") + 
  theme_minimal() + 
  labs(y = "Observations", title = "Liveness")

ggplot(songs_clean, aes(x = Stream)) + geom_histogram(fill = "#9a0331ff") + 
  theme_minimal() + 
  labs(y = "Observations", title = "Streams")

ggplot(songs_clean, aes(x = Key)) + geom_histogram(fill = "#9a0331ff") + 
  theme_minimal() + 
  labs(y = "Observations", title = "Key")


ggplot(songs_clean, aes(x = official_video, y = ViewsM)) + geom_boxplot(fill = "#9a0331ff") + 
  theme_minimal() + 
  labs(y = "Views (Millions)", x = "Official Video", title = "Official Video")

# distribution of views and likes
ggplot(songs_clean, aes(x = ViewsM)) + 
  geom_histogram(bins = 20, fill = "#9a0331ff", color = "#9a0331ff") + 
  theme_minimal() + 
  labs(x = "Views (Millions)", y = "Observations", title = "Distribution of Views")

# me trying to figure out what the outlier is... it's despacito
songs_popular <- songs_clean %>% arrange(-Views) %>% slice(1:50)
summary(songs_popular)

```


Linear Regression Modeling

```{r}

# linear regression with 80/20 train test split

# splitting the data set
set.seed(310)
songs_split <- initial_split(songs_clean, prop = 0.8)
songs_train <- training(songs_split)
songs_test <- testing(songs_split)

dim(songs_split)

# train linear model ORIGINAL
mod1 <- lm(ViewsM ~ Danceability + Energy + Key + Loudness + Speechiness + 
               Acousticness + Instrumentalness + Valence + Tempo + Duration_ms + 
               Licensed + official_video + Stream,
             songs_train)

summary(mod1)

## POST PRESENTATION EDITS
# train linear model POST PRESENTATION
mod1new <- lm(logViewsM ~ Danceability + Energy + Key + Loudness + Speechiness + 
                Acousticness + Instrumentalness + Liveness + Valence + Tempo + logDuration + 
                Licensed + official_video + topArtist,
              songs_train)

summary(mod1new)

# train new model with only ** and *** significant variables ORIGINAL
mod2 <- lm(ViewsM ~ Danceability + Loudness + Acousticness + Valence + Duration_ms + Licensed + Stream,
           songs_train)

summary(mod2)

# edited linear regression model POST PRESENTATION
mod2new <- lm(logViewsM ~ Danceability + Energy + Loudness + Speechiness + 
                Instrumentalness + Tempo + logDuration + Licensed + official_video + topArtist,
              songs_train)

summary(mod2new)

# THE FIRST MODEL (mod1new) PERFORMED BETTER SO GO WITH THAT ONE

```

Linear Regression Accuracy Metrics

```{r}

# code for linear regression Metrics
songs_clean %>%  glimpse()
# splitting the data set
set.seed(310)
songs_split <- initial_split(songs_clean, prop = 0.8)
songs_train <- training(songs_split)
songs_test <- testing(songs_split)

#creating the model
mod1 <- lm(ViewsM ~ Danceability + Energy + Key + Loudness + Speechiness + 
             Acousticness + Instrumentalness + Liveness + Valence + Tempo + Duration_ms + 
             Licensed + official_video + Stream,
           songs_train)

summary(mod1)

## Significant at a 0.001 level: Danceability Loudness LicensedTRUE
## At 0.01 level: Energy
## At 0.05 level: Speechiness official_videoTRUE
## Not significant: Key Acousticness Instrumentalness Liveness valence Tempo Duration_ms

# train new model with only significant variables
mod2 <- lm(ViewsM ~ Danceability + Loudness + Acousticness + Valence + Duration_ms + Licensed + Stream,
           songs_train)

summary(mod2)

#model predictions and accuracy ; additions to model code

#mod2
mod2_preds_train <- predict(mod2, newdata = songs_train)
mod2_preds_test <- predict(mod2, newdata = songs_test)

mod2_preds_train_results <- songs_train %>% mutate(views_pred = mod2_preds_train)
mod2_preds_test_results <- songs_test %>% mutate(views_pred = mod2_preds_test)

mod2_train_rmse <- RMSE(mod2_preds_train, songs_train$ViewsM)
mod2_test_rmse <- RMSE(mod2_preds_test, songs_test$ViewsM)

mod2_train_rmse
mod2_test_rmse


#Creates dataframe and plots real vs predicted values, unused

#train_residual_df <- data.frame(
#  real = songs_train$ViewsM,
#  predicted = mod2_preds_train)
#)

#ggplot(train_residual_df, aes(x = real, y = predicted)) +
#  geom_point(alpha = 0.1) +
#  theme_minimal()
  

#creating RMSE data frame for mod2 
rmse_df <- data.frame(
  scores = c(mod2_train_rmse, mod2_test_rmse)
)

rmse_df %>% glimpse()

ggplot(rmse_df, aes(x = scores, y = scores, fill = "#9a0331ff")) + 
  geom_bar(stat = "identity")+ # sets height of bars equal to their value
  theme_minimal() +
  labs(x = 'Train & Test sets', y ='RMSE Value (millions)', title = 'Comparison of RMSE for Mod2') +
  geom_text(aes(label= scores), vjust=0) # creates value labels 

```

Random Forest with Metrics

```{r}

# code for random forest model

# data cleaning and exploring
songs %>% glimpse()
songs %>% is.na %>% sum()

# factor binary variables
songs_clean <- songs_clean %>% mutate(Artist = factor(Artist),
                                      Licensed = as.logical(Licensed),
                                      official_video = as.logical(official_video))

songs_clean %>% glimpse()

set.seed(310)
songs_split <- initial_split(songs_clean, prop = 0.8)
songs_train <- training(songs_split)
songs_test <- testing(songs_split)


# random forest model
rf_songs <- randomForest(ViewsM ~ Danceability + Energy + Key + Loudness + Speechiness + 
                           Acousticness + Instrumentalness + Liveness + Valence +
                           Tempo + Duration_ms + Stream +
                           Licensed + official_video,
                         data = songs_train,
                         importance = TRUE)

print(rf_songs)
plot(rf_songs)

# performance of the model
rf_train <- predict(rf_songs, newdata = songs_train)

rf_test <- predict(rf_songs, newdata = songs_test)

RMSE(rf_train, songs_train$ViewsM)
RMSE(rf_test, songs_test$ViewsM)

importance(rf_songs)

# importance plot
varImpPlot(rf_songs)

```

Random Forest with Changes

```{r}

# code for 

# data cleaning and exploring
songs_clean %>% glimpse()

# 80/20 train-test split
set.seed(310)
songs_split <- initial_split(songs_clean, prop = 0.8)
songs_train <- training(songs_split)
songs_test <- testing(songs_split)

# new random forest model with updated variables
rf2_songs <- randomForest(logViewsM ~ Danceability + Energy + Key + Loudness + Speechiness + 
                Acousticness + Instrumentalness + Liveness + Valence + Tempo + logDuration + 
                Licensed + official_video + topArtist,
              data = songs_train,
              ntree = 500,
              mtry = 4,
              importance = TRUE)
print(rf2_songs)
plot(rf2_songs)

# performance of the model
rf2_train <- predict(rf2_songs, newdata = songs_train)

rf2_test <- predict(rf2_songs, newdata = songs_test)


# big improvement on train and test data
RMSE(rf2_train, songs_train$logViewsM)
RMSE(rf2_test, songs_test$logViewsM)

# variable importance of 2nd model
importance(rf2_songs)

# variable importance plot 2nd model
varImpPlot(rf2_songs)

# plot min depth distribution of 2nds model
plot_min_depth_distribution(rf2_songs)


# 3rd model with tuning to check for improvement
rf3_songs <- randomForest(logViewsM ~ Danceability + Energy + Key + Loudness + Speechiness + 
                           Acousticness + Instrumentalness + Liveness + Valence + Tempo + logDuration + 
                           Licensed + official_video + topArtist,
                         data = songs_train,
                         ntree = 200,
                         mtry = 7,
                         importance = TRUE)
plot(rf3_songs)
print(rf3_songs)

# performance of the 3rd model
rf3_train <- predict(rf3_songs, newdata = songs_train)

rf3_test <- predict(rf3_songs, newdata = songs_test)

# slightly improved train but test was pretty much the same
RMSE(rf3_train, songs_train$logViewsM)
RMSE(rf3_test, songs_test$logViewsM)

# variable importance for 3rd model
importance(rf3_songs)

# variable importance plot of 3rd mdodel
varImpPlot(rf3_songs)

```



